Epoch 1/100
111/111 [==============================] - 251s 2s/step - loss: 255.6281 - val_loss: 9.0658
Epoch 2/100
111/111 [==============================] - 234s 2s/step - loss: 16.1938 - val_loss: 11.0128
Epoch 3/100
111/111 [==============================] - 236s 2s/step - loss: 13.9658 - val_loss: 5.3326
Epoch 4/100
111/111 [==============================] - 235s 2s/step - loss: 12.1099 - val_loss: 5.1227
Epoch 5/100
111/111 [==============================] - 236s 2s/step - loss: 11.4375 - val_loss: 4.6725
Epoch 6/100
111/111 [==============================] - 233s 2s/step - loss: 11.0095 - val_loss: 4.0675
Epoch 7/100
111/111 [==============================] - 236s 2s/step - loss: 9.8890 - val_loss: 3.4032
Epoch 8/100
111/111 [==============================] - 234s 2s/step - loss: 9.5517 - val_loss: 3.7143
Epoch 9/100
111/111 [==============================] - 230s 2s/step - loss: 9.0843 - val_loss: 3.3139
Epoch 10/100
111/111 [==============================] - 223s 2s/step - loss: 8.8413 - val_loss: 3.5847
Epoch 11/100
111/111 [==============================] - 222s 2s/step - loss: 8.4968 - val_loss: 3.1147
Epoch 12/100
111/111 [==============================] - 222s 2s/step - loss: 8.0003 - val_loss: 2.8726
Epoch 13/100
111/111 [==============================] - 222s 2s/step - loss: 7.6903 - val_loss: 2.7369
Epoch 14/100
111/111 [==============================] - 221s 2s/step - loss: 7.0783 - val_loss: 3.2258
Epoch 15/100
111/111 [==============================] - 223s 2s/step - loss: 7.2589 - val_loss: 2.7449
Epoch 16/100
111/111 [==============================] - 223s 2s/step - loss: 6.7637 - val_loss: 2.4062
Epoch 17/100
111/111 [==============================] - 225s 2s/step - loss: 6.6179 - val_loss: 2.3946
Epoch 18/100
111/111 [==============================] - 222s 2s/step - loss: 6.1188 - val_loss: 2.7196
Epoch 19/100
111/111 [==============================] - 223s 2s/step - loss: 5.9786 - val_loss: 2.2050
Epoch 20/100
111/111 [==============================] - 223s 2s/step - loss: 5.7788 - val_loss: 3.1989
Epoch 21/100
111/111 [==============================] - 222s 2s/step - loss: 5.8016 - val_loss: 2.7133
Epoch 22/100
111/111 [==============================] - 234s 2s/step - loss: 5.3276 - val_loss: 3.0165
Epoch 23/100
111/111 [==============================] - 233s 2s/step - loss: 5.4510 - val_loss: 2.1176
Epoch 24/100
111/111 [==============================] - 223s 2s/step - loss: 5.1086 - val_loss: 2.0625
Epoch 25/100
111/111 [==============================] - 222s 2s/step - loss: 4.9901 - val_loss: 2.0159
Epoch 26/100
111/111 [==============================] - 223s 2s/step - loss: 4.7381 - val_loss: 2.1296
Epoch 27/100
111/111 [==============================] - 221s 2s/step - loss: 4.5532 - val_loss: 3.1035
Epoch 28/100
111/111 [==============================] - 222s 2s/step - loss: 4.6365 - val_loss: 1.8806
Epoch 29/100
111/111 [==============================] - 221s 2s/step - loss: 4.7422 - val_loss: 2.1518
Epoch 30/100
111/111 [==============================] - 221s 2s/step - loss: 4.3626 - val_loss: 2.0561
Epoch 31/100
111/111 [==============================] - 220s 2s/step - loss: 3.9757 - val_loss: 2.4910
Epoch 32/100
111/111 [==============================] - 221s 2s/step - loss: 3.9418 - val_loss: 1.9635
Epoch 33/100
111/111 [==============================] - 222s 2s/step - loss: 3.7104 - val_loss: 1.9946
Epoch 34/100
111/111 [==============================] - 221s 2s/step - loss: 3.6147 - val_loss: 1.6744
Epoch 35/100
111/111 [==============================] - 221s 2s/step - loss: 3.6494 - val_loss: 1.7481
Epoch 36/100
111/111 [==============================] - 221s 2s/step - loss: 3.6977 - val_loss: 1.7466
Epoch 37/100
111/111 [==============================] - 221s 2s/step - loss: 4.0269 - val_loss: 1.5503
Epoch 38/100
111/111 [==============================] - 221s 2s/step - loss: 3.6481 - val_loss: 1.5077
Epoch 39/100
111/111 [==============================] - 220s 2s/step - loss: 3.4180 - val_loss: 1.6107
Epoch 40/100
111/111 [==============================] - 221s 2s/step - loss: 3.7649 - val_loss: 2.0664
Epoch 41/100
111/111 [==============================] - 221s 2s/step - loss: 3.3122 - val_loss: 1.3994
Epoch 42/100
111/111 [==============================] - 220s 2s/step - loss: 3.0821 - val_loss: 1.5558
Epoch 43/100
111/111 [==============================] - 220s 2s/step - loss: 3.0959 - val_loss: 1.3164
Epoch 44/100
111/111 [==============================] - 220s 2s/step - loss: 2.9368 - val_loss: 1.3654
Epoch 45/100
111/111 [==============================] - 220s 2s/step - loss: 2.8911 - val_loss: 1.4132
Epoch 46/100
111/111 [==============================] - 220s 2s/step - loss: 2.9839 - val_loss: 1.1913
Epoch 47/100
111/111 [==============================] - 221s 2s/step - loss: 2.8458 - val_loss: 1.2611
Epoch 48/100
111/111 [==============================] - 220s 2s/step - loss: 2.8773 - val_loss: 1.3085
Epoch 49/100
111/111 [==============================] - 220s 2s/step - loss: 2.7922 - val_loss: 1.2188
Epoch 50/100
111/111 [==============================] - 220s 2s/step - loss: 2.8702 - val_loss: 1.8555
Epoch 51/100
111/111 [==============================] - 220s 2s/step - loss: 2.7500 - val_loss: 1.2967
Epoch 52/100
111/111 [==============================] - 220s 2s/step - loss: 2.6750 - val_loss: 1.1073
Epoch 53/100
111/111 [==============================] - 221s 2s/step - loss: 2.6881 - val_loss: 1.1123
Epoch 54/100
111/111 [==============================] - 220s 2s/step - loss: 2.6239 - val_loss: 1.3371
Epoch 55/100
111/111 [==============================] - 220s 2s/step - loss: 2.9680 - val_loss: 1.7018
Epoch 56/100
111/111 [==============================] - 220s 2s/step - loss: 2.7602 - val_loss: 1.1189
Epoch 57/100
111/111 [==============================] - 220s 2s/step - loss: 2.5162 - val_loss: 1.5764
Epoch 58/100
111/111 [==============================] - 221s 2s/step - loss: 2.7406 - val_loss: 1.7932
Training model complete...
dict_keys(['loss', 'val_loss'])
Loss
[255.62813792357574, 16.18898030903034, 13.948277197880893, 12.104786215313045, 11.439945435930028, 10.99739303498561, 9.88518303411604, 9.549174042306058, 9.08390209543588, 8.841267852090406, 8.481424531282261, 7.991150366140418, 7.69337410361057, 7.080984771938242, 7.262631942860087, 6.760084360768437, 6.619232658817274, 6.12136360377644, 5.976738127269776, 5.77818535980037, 5.8049930511249785, 5.329416338912709, 5.456274126673004, 5.109769227908918, 4.9866127033434475, 4.7390334789984285, 4.556128403128065, 4.6414005451594615, 4.742646865596721, 4.362285592650181, 3.969558575643464, 3.9448068975248183, 3.7111729824132746, 3.611205501090039, 3.6498941472120716, 3.692873110948759, 4.027860172038684, 3.6502748658299726, 3.41955389694126, 3.7631205915351713, 3.3046980479708594, 3.0821439975243594, 3.0970991295509966, 2.9346570087805137, 2.894534465559177, 2.9864017895679744, 2.845107182353876, 2.877548385379121, 2.7913188095455346, 2.874461263559301, 2.7498097748952186, 2.6777107708530457, 2.6871405537579474, 2.6236706828322984, 2.9729196985790094, 2.757520376334434, 2.5160077206364506, 2.73979884949213]
Validation Loss
[9.065771600033374, 11.012779596173397, 5.332574668649997, 5.122693934650702, 4.672462025376283, 4.067526221752804, 3.403155723783139, 3.7143100718153175, 3.3138668737678882, 3.5846884597605158, 3.114742025354994, 2.8725677205023366, 2.736946692294845, 3.2257829358644576, 2.744854784139167, 2.4061522480642523, 2.3945600273453187, 2.7196124427627337, 2.2049621108058934, 3.1988699318410876, 2.7133410104285574, 3.0165127886630825, 2.1176248975048395, 2.0625388873753465, 2.0159385325275214, 2.129625184513698, 3.1034731845830246, 1.880572900275522, 2.1517582060657294, 2.0561237955921006, 2.491040861813503, 1.9635337767836567, 1.9946426192972466, 1.6744469418544794, 1.7480838305163924, 1.7465843829675733, 1.550309162751059, 1.5076883206857699, 1.6107428742346364, 2.0663937139256454, 1.3993766250533957, 1.5558184600162888, 1.3164006546438138, 1.3653961192463364, 1.413218170205487, 1.1912977485376621, 1.2611474888983651, 1.3084896182186294, 1.2187829093730196, 1.8555455709172186, 1.2966571274363947, 1.107349030325346, 1.1122987536944757, 1.3370900594981237, 1.70182948819149, 1.1188784120716304, 1.576378599823874, 1.7931565684533723]
Saving model...
Model Saved.

